{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["edXsDMX3NKVk","psUZ3YXNpELM","Xp3xraBdpOAX","dG_HWVhooDQX"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"edXsDMX3NKVk"}},{"cell_type":"code","source":["from google.colab import drive\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import numpy as np\n","import re\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"-p_RwtavxrfP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rDNXicl-npbW","executionInfo":{"status":"ok","timestamp":1751202591329,"user_tz":-120,"elapsed":18848,"user":{"displayName":"Francesco Volpi Ghirardini","userId":"04183541609253486658"}},"outputId":"207967c8-4fd7-4ae0-cfd1-8c04d8bdf72f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Giro d'Italia"],"metadata":{"id":"psUZ3YXNpELM"}},{"cell_type":"markdown","source":["## Technical Info"],"metadata":{"id":"FSormbHo_TLH"}},{"cell_type":"markdown","source":["Each stage number is put as key in the \"stages_info\" dictionary, with the associated value being the dataframe containing the stage's technical information."],"metadata":{"id":"ZRrbp2Uz3oNq"}},{"cell_type":"code","source":["# Sending the request to the page with all the stages\n","url = \"https://www.giroditalia.it/en/the-route/\"\n","response = requests.get(url)\n","giro_page_text = response.text\n","soup = BeautifulSoup(giro_page_text, 'html.parser')\n","\n","# Storing the links to all the stages\n","list_temp = soup.find('div', {'class':'list-tappe'}).find_all('a')\n","stages_list = [ele.get('href') for ele in list_temp]"],"metadata":{"id":"iXMBs9zABo-R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dict to translate stage type\n","type_dict = {'collinare' : 'Hill',\n","             'crono' : 'Time trial',\n","             'pianeggiante' : 'Flat',\n","             'montagna': 'Mountain'}\n","\n","# Empty dict to store the dataframes\n","stages_info = {}\n","\n","for stage in range(1,22):\n","  stage_dict = {}\n","  # Sending the requests to the stage link\n","  url = stages_list[stage-1]\n","  response = requests.get(url)\n","  giro_page_text = response.text\n","  soup = BeautifulSoup(giro_page_text, 'html.parser')\n","\n","  # Extracting all of the informations\n","  stage_dict['Start'] = soup.find_all('h2')[0].text.strip()\n","  stage_dict['Finish'] = soup.find_all('h2')[1].text.strip()\n","  stage_type = soup.find('section',{'class':'tappa-body post-tappa'}).get('data-tipologia')\n","  stage_dict['Type'] = stage_type.replace(stage_type, type_dict[stage_type])\n","  stage_dict['Difficulty'] = soup.find('section',{'class':'tappa-body post-tappa'}).get('data-difficulty') + '/5'\n","  stage_dict['Lenght'] = soup.find('span',{'class':'km d-none-mobile'}).text\n","  stage_dict['Altitude Gain'] = re.search(r'Altitude Gain (.*)', soup.find('span',{'class':'dislivello d-none-mobile'}).text).group(1)\n","  stage_dict['Technical Info'] = soup.find('div',{'class':'js-tab-info-tecniche'}).find('p').text.strip().replace(u'Final kilometres', u' ')\n","\n","  # Storing the informations in a series that's in the 'stages_info' dictionary\n","  stages_info[stage] = pd.Series(stage_dict, name=f\"Info Stage {stage}\")"],"metadata":{"id":"aEiu_bzqouMu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Weather"],"metadata":{"id":"Lh4MIW-wZlGd"}},{"cell_type":"markdown","source":["Each stage number is put as key in the \"stages_weather\" dictionary, with the associated value being the dataframe containing the stage's weather information."],"metadata":{"id":"-WgVoocy4STo"}},{"cell_type":"code","source":["# Empty dict to store the dataframes\n","stages_weather = {}\n","\n","for stage in range(1,22):\n","  # Sending a request to the 3BMeteo Giro widget\n","  url = f\"https://www.3bmeteo.com/meteogiro/widget_meteo/{stage}\"\n","  response = requests.get(url)\n","  giro_page_text = response.text\n","  soup = BeautifulSoup(giro_page_text, 'html.parser')\n","\n","  # Making the column headers and index\n","  keys_list = ['Temperature', 'Conditions', 'Place', 'Precipitation', 'Wind - Speed', 'Wind - Direction']\n","  index = ['Start', 'Finish']\n","  values_list = []\n","\n","  # Extracting all the info for both start and arrival places\n","  for i in soup.find_all('div', {'class':'row'}):\n","    part1 = [ele.text.strip() for ele in i.find_all('span')[:3]]\n","    part2 = [ele.text.strip() for ele in i.find_all('b')]\n","    values_list.append(part1 + part2)\n","\n","  # Storing the informations in a series that's in the 'stages_weather' dictionary\n","  stages_weather[stage] = pd.DataFrame(values_list, columns=keys_list, index=index)"],"metadata":{"id":"Tnxp3S9UmaAP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Stage Rankings"],"metadata":{"id":"JGcgOWXE_NOU"}},{"cell_type":"markdown","source":["A dataframe is created for each ranking table present in each stage.\n","\n","Each stage number is put as key in the \"stages_rankings\" dictionary, with the associated value being a list containing all the names of the rankings dataframes for the stage."],"metadata":{"id":"eZgHcSj_4dXR"}},{"cell_type":"code","source":["# Empty dict to store the lists containing the dataframes' names\n","stages_rankings = {}\n","\n","for stage in range(1,22):\n","  # Sending a request to the stage rankings page\n","  url = f\"https://www.giroditalia.it/en/classifiche/di-tappa/{stage}/\"\n","  response = requests.get(url)\n","  giro_page_text = response.text\n","  soup = BeautifulSoup(giro_page_text, 'html.parser')\n","\n","  # Empty list to store the dataframes' names\n","  tables_list = []\n","\n","  # Going over each of the rankings for the stage\n","  for table in soup.find('div',{'class':'wrapper-tabs'}).find_all('div',{'class':'single-tab'}):\n","\n","    # Extracting the name of the table\n","    table_name = table.find('div',{'class':'description-leaderboard'}).text.strip().replace(u'\\xa0', u' ')\n","    table_name = re.sub(r\"[\\s'\\-:\\./]+\", '_', table_name)\n","\n","    # Extracting the headers\n","    keys_list = []\n","    keys = table.find('div',{'class':'header-table'}).find_all('div')\n","    keys_list = [ele.text.strip() for ele in keys]\n","\n","    # Extracting the values\n","    values_list = []\n","    if 'Team' in table_name:\n","      for i in table.find_all('div',{'class':'line-table'}):\n","        temp = i.find_all('div')\n","        values = [ele.text.strip() for ele in temp]\n","        values_list.append(values)\n","    else:\n","      for i in table.find_all('div',{'class':'line-table'}):\n","        temp = i.find_all('div')\n","        values = [ele.text.strip() for ele in temp]\n","        values_list.append([values[0]] + values[5:])\n","\n","    # Making a dataframe with the table and storing its name into the list of tables of the stage\n","    exec(f\"{table_name} = pd.DataFrame(values_list, columns=keys_list)\")\n","    tables_list.append(table_name)\n","\n","    # Formatting the table\n","    if 'Team' not in table_name:\n","      if 'withdrawals' not in table_name:\n","        exec(f\"{table_name}.insert(0, 'Position', {table_name}['Rider'].str.extract(r'(^\\d+)', expand=False))\")\n","        exec(f\"{table_name}['Rider'] = {table_name}['Rider'].str.extract(r'\\s+(.*)', expand=False).str.title()\")\n","      else: exec(f\"{table_name}['Rider'] = {table_name}['Rider'].str.title()\")\n","    exec(f\"{table_name}['Team'] = {table_name}['Team'].str.title()\")\n","\n","  # Storing the list of tables of the stage into the 'stages_rankings' dict\n","  stages_rankings[stage] = tables_list"],"metadata":{"id":"vCexTJ9glElz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Stage 9 Missing Values:**"],"metadata":{"id":"cl0zl_i9n9RT"}},{"cell_type":"markdown","source":["Some informations are missing from the website's data, they are added manually."],"metadata":{"id":"h0SqhQy248Sr"}},{"cell_type":"code","source":["# Adding withrawals\n","Stage_9_official_withdrawals.loc[1] = ['Andrea Pasqualon', 'Bahrain Victorious']"],"metadata":{"id":"8OzOuoT0O1Ay"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Making the table values\n","missing_9_dict = {}\n","missing_9_dict['Position']  = [103 for x in range (0,69)]\n","missing_9_dict['Rider'] = [x for x in Stage_10_Order_of_arrival['Rider'].to_list() if x not in Stage_9_Order_of_arrival['Rider'].to_list()]\n","missing_9_dict['Time'] = ['4:38:13' for x in range (0,69)]\n","missing_9_dict['Time bonus'] = ['-' for x in range (0,69)]\n","missing_9_dict['Gap'] = ['0:00' for x in range (0,69)]\n","\n","# Storing the values in a dataframe and concatenating it to the order of arrival\n","missing_9 = pd.merge(pd.DataFrame(missing_9_dict), Stage_1_Order_of_arrival[['Rider', 'Team']], left_on='Rider', right_on='Rider')\n","Stage_9_Order_of_arrival = pd.concat([Stage_9_Order_of_arrival, missing_9], ignore_index = True)"],"metadata":{"id":"KLd162I8orlT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Overall Rankings"],"metadata":{"id":"ZdL7WVPTmyE3"}},{"cell_type":"markdown","source":["A dataframe is created for each overall ranking table present for each stage.\n","\n","Each stage number is put as key in the \"overall_rankings\" dictionary, with the associated value being a list containing all the names of the rankings dataframes for the stage."],"metadata":{"id":"sclzNcl_5GGL"}},{"cell_type":"code","source":["# Making the dictionary where the list containing all the table names will be stored\n","overall_rankings = dict((key,[]) for key in range(1,22))"],"metadata":{"id":"LI8JbClBoVA2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Making a dictionary with lists containing all the withdrawals for each stage\n","wtdrw_dict = dict((key,[x for x in value if 'withdrawals' in x]) for key,value in stages_rankings.items())\n","wtdrw_dict = dict((key,eval(value.pop())['Rider'].to_list() if value!=[] else value) for key,value in wtdrw_dict.items())"],"metadata":{"id":"eLFfEA0__95C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Point Based Rankings**"],"metadata":{"id":"qXEQj5u9A9Wi"}},{"cell_type":"code","source":["# Dictionary with as key the substring of the name of the tables to parse and as value the overall rankings table name\n","overall_dict = {'Points' : 'Maglia_Ciclamino',\n","                'KOM' : 'Maglia_Azzurra',\n","                'Intermediate_Sprint' : 'Intermediate_Sprint',\n","                'Red_Bull_KM' : 'Red_Bull_KM_Overall',\n","                'Fuga' : 'Fuga_Overall'}\n","\n","for val_find, val_name in overall_dict.items():\n","\n","  # Making a dictionary\n","  exec(f\"{val_find}_dict = dict((key,[x for x in value if '{val_find}' in x]) for key,value in stages_rankings.items())\")\n","\n","  # Updating the list of tables in 'overall_rankings' and making the first dataframe\n","  for key,value in eval(f\"{val_find}_dict\").items():\n","    exec(f\"Stage_{val_find}_{key} = pd.DataFrame()\")\n","    for x in range(0,len(value)):\n","      exec(f\"Stage_{val_find}_{key} = Stage_{val_find}_{key}.add({value[x]}.drop(['Position', 'Team'], axis=1).set_index('Rider').astype(int), fill_value=0)\")\n","\n","  # Updating the list of tables and making all the other tables\n","  overall_rankings[1].append(f\"Stage_{1}_{val_name}\")\n","  exec(f\"Stage_1_{val_name} = Stage_{val_find}_1\")\n","  for key in range(2,22):\n","    overall_rankings[key].append(f\"Stage_{key}_{val_name}\")\n","    exec(f\"Stage_{key}_{val_name} = Stage_{key-1}_{val_name}.add(Stage_{val_find}_{key}, fill_value=0).drop({wtdrw_dict[key]}, errors='ignore')\")\n","\n","  # Formatting the data and storing the information in a dataframe\n","  for key in range(1,22):\n","    exec(f\"Stage_{key}_{val_name} = Stage_{key}_{val_name}.sort_values('Points', ascending=False).reset_index().reset_index().rename({{'index':'Position'}}, axis=1)\")\n","    exec(f\"Stage_{key}_{val_name}['Position'] = Stage_{key}_{val_name}['Position'] + 1\")\n","    exec(f\"Stage_{key}_{val_name} = pd.merge(Stage_{key}_{val_name}, Stage_1_Order_of_arrival[['Rider', 'Team']], left_on='Rider', right_on='Rider', how='left')[['Position', 'Rider', 'Team', 'Points']]\")"],"metadata":{"id":"eGEUKULNSdVU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Time Based Rankings**"],"metadata":{"id":"P9puo_ldBFKa"}},{"cell_type":"code","source":["# Updating the list of tables in 'overall_rankings' and making the first dataframe\n","overall_rankings[1].insert(0, f\"Stage_{1}_Maglia_Rosa\")\n","Stage_1_Maglia_Rosa = pd.to_timedelta(Stage_1_Order_of_arrival.set_index('Rider')['Time']) - pd.to_timedelta('00:0'+Stage_1_Order_of_arrival.set_index('Rider')['Time bonus'].replace('-', '0:00').rename('Time'))\n","\n","# Updating the list of tables and making all the other tables\n","for key in range(2,22):\n","  overall_rankings[key].insert(0, f\"Stage_{key}_Maglia_Rosa\")\n","  if len(eval(f\"Stage_{key}_Order_of_arrival.loc[0]['Time']\")) == 7:\n","    exec(f\"Stage_{key}_Maglia_Rosa = Stage_{key-1}_Maglia_Rosa.add(pd.to_timedelta(Stage_{key}_Order_of_arrival.set_index('Rider')['Time']) - pd.to_timedelta('00:0'+Stage_{key}_Order_of_arrival.set_index('Rider')['Time bonus'].replace('-', '0:00').rename('Time')), fill_value=pd.to_timedelta('00:00:00')).drop({wtdrw_dict[key]}, errors='ignore')\")\n","  else: exec(f\"Stage_{key}_Maglia_Rosa = Stage_{key-1}_Maglia_Rosa.add(pd.to_timedelta('00:'+Stage_{key}_Order_of_arrival.set_index('Rider')['Time']) - pd.to_timedelta('00:0'+Stage_{key}_Order_of_arrival.set_index('Rider')['Time bonus'].replace('-', '0:00').rename('Time')), fill_value=pd.to_timedelta('00:00:00')).drop({wtdrw_dict[key]}, errors='ignore')\")\n","\n","# Formatting the data and storing the information in a dataframe\n","for key in range(1,22):\n","  exec(f\"Stage_{key}_Maglia_Rosa = Stage_{key}_Maglia_Rosa.sort_values().reset_index().reset_index().rename({{'index':'Position'}}, axis=1)\")\n","  exec(f\"Stage_{key}_Maglia_Rosa['Position'] = Stage_{key}_Maglia_Rosa['Position'] + 1\")\n","  exec(f\"Stage_{key}_Maglia_Rosa = pd.merge(Stage_{key}_Maglia_Rosa, Stage_1_Order_of_arrival[['Rider', 'Team']], left_on='Rider', right_on='Rider', how='left')[['Position', 'Rider', 'Team', 'Time']]\")"],"metadata":{"id":"gqCPTeJ6q4Ab"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Making a function to correctly format the time\n","def get_time(time):\n","  hours = str(time.components.days*24 + time.components.hours)\n","  minutes = str(time.components.minutes)\n","  seconds = str(time.components.seconds)\n","\n","  if len(minutes) == 2: temp = hours + ':' + minutes\n","  else: temp = hours + ':0' + minutes\n","\n","  if len(seconds) == 2: temp = temp + ':' + seconds\n","  else: temp = temp + ':0' + seconds\n","\n","  return temp\n","\n","\n","# Applying the function to all of the dataframes\n","for x in range(1,22):\n","  exec(f\"Stage_{x}_Maglia_Rosa['Time'] = Stage_{x}_Maglia_Rosa['Time'].apply(get_time)\")"],"metadata":{"id":"SaXk_hFRkdLY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Gran Piemonte"],"metadata":{"id":"Xp3xraBdpOAX"}},{"cell_type":"markdown","source":["## Technical Info"],"metadata":{"id":"UIWcitU2tsED"}},{"cell_type":"markdown","source":["A dataframe containing the technical informations of the race is created."],"metadata":{"id":"ACWEy5_967Lm"}},{"cell_type":"code","source":["# Dict to translate stage type\n","type_dict = {'collinare' : 'Hill',\n","             'crono' : 'Time trial',\n","             'pianeggiante' : 'Flat',\n","             'montagna': 'Mountain'}\n","\n","\n","# Empty dict to store the informations\n","gp_dict = {}\n","\n","# Sending the request to the informations page\n","url = \"https://www.ilgranpiemonte.it/en/archive_stages/valdengo-borgomanero/\"\n","response = requests.get(url)\n","gp_page_text = response.text\n","soup = BeautifulSoup(gp_page_text, 'html.parser')\n","\n","# Extracting all of the informations\n","gp_dict['Start'] = soup.find_all('h2')[0].text.strip()\n","gp_dict['Finish'] = soup.find_all('h2')[1].text.strip()\n","race_type = soup.find('section',{'class':'tappa-body post-tappa'}).get('data-tipologia')\n","gp_dict['Type'] = race_type.replace(race_type, type_dict[race_type])\n","gp_dict['Difficulty'] = 'None'\n","gp_dict['Lenght'] = soup.find('span',{'class':'km d-none-mobile'}).text\n","gp_dict['Altitude Gain'] = re.search(r'Altitude gain (.*)', soup.find('span',{'class':'dislivello d-none-mobile'}).text).group(1)\n","gp_dict['Technical Info'] = soup.find('div',{'class':'js-tab-info-tecniche'}).find('p').text.strip().replace(u'Final kilometres', u' ')\n","\n","# Converting 'gp_dict' to dataframe\n","Gran_Piemonte_Info = pd.Series(gp_dict, name=\"Info Gran Piemonte\")"],"metadata":{"id":"WxgRrEzFtsEE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Weather"],"metadata":{"id":"KWYDAWnmz5Un"}},{"cell_type":"markdown","source":["A dataframe containing the weather informations of the race is created."],"metadata":{"id":"Osx7P83Y7Gew"}},{"cell_type":"code","source":["keys_list = ['Temperature', 'Conditions', 'Place', 'Precipitation', 'Wind - Speed', 'Wind - Direction']\n","\n","index=['Start', 'Finish']\n","\n","values_list = [['21°', 'pioggia', 'Valdengo', '4', '6', 'None'],\n","               ['15°', 'pioggia', 'Borgomanero', '19', '6.3', 'None']]\n","\n","Gran_Piemonte_Weather = pd.DataFrame(values_list, columns=keys_list, index=index)"],"metadata":{"id":"hn_C1H9bA8uA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Order of Arrival"],"metadata":{"id":"qAIDH0zvz7vL"}},{"cell_type":"markdown","source":["A dataframe containing the order of arrival of the race is created."],"metadata":{"id":"A083E-Ip7O1O"}},{"cell_type":"code","source":["# Sending the request to the rankings page\n","url = \"https://www.ilgranpiemonte.it/en/archivio-classifiche/2024/\"\n","response = requests.get(url)\n","gp_page_text = response.text\n","soup = BeautifulSoup(gp_page_text, 'html.parser')\n","\n","# Making the list with the table headers\n","keys = ['Rider', 'Team', 'Time', 'Time Bonus', 'Gap']\n","\n","# Extracting all of the informations\n","values_list = []\n","for i in soup.find_all('div',{'class':'line-table'}):\n","  temp = i.find_all('div')\n","  values = [ele.text.strip() for ele in temp]\n","  values_list.append([values[0]] + values[7:])\n","\n","# Storing all of the informations into a dataframe\n","Gran_Piemonte_Order_of_arrival = pd.DataFrame(values_list, columns=keys)\n","\n","# Formatting the dataframe\n","Gran_Piemonte_Order_of_arrival.insert(0, 'Position', Gran_Piemonte_Order_of_arrival['Rider'].str.extract(r'(^\\d+)', expand=False))\n","Gran_Piemonte_Order_of_arrival['Rider'] = Gran_Piemonte_Order_of_arrival['Rider'].str.extract(r'\\s+(.*)', expand=False).str.title()\n","Gran_Piemonte_Order_of_arrival['Team'] = Gran_Piemonte_Order_of_arrival['Team'].str.title()"],"metadata":{"id":"H_lcNugl69jZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Saving"],"metadata":{"id":"dG_HWVhooDQX"}},{"cell_type":"markdown","source":["**Stage 20:**"],"metadata":{"id":"6-6KvNPVrkP9"}},{"cell_type":"code","source":["stages_info[20].to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_20/Stage_20_Info.csv\")"],"metadata":{"id":"nLbEgE4NoCfW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stages_weather[20].to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_20/Stage_20_Weather.csv\")"],"metadata":{"id":"FmZ8P4xxqNxG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_20_Order_of_arrival.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_20/Stage_20_Order_of_arrival.csv\")"],"metadata":{"id":"uPDRyg8Oqed_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_20_Points_Stage_Standing.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_20/Stage_20_Points_Stage_Standing.csv\")"],"metadata":{"id":"5omg10lOqfHU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_20_KOM_Corio_km_69.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_20/Stage_20_KOM_Corio_km_69.csv\")"],"metadata":{"id":"ks_vxxIWqf8S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_20_KOM_Colle_del_Lys_km_115.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_20/Stage_20_KOM_Colle_del_Lys_km_115.csv\")"],"metadata":{"id":"JPKuIRNgqhGj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_20_KOM_Colle_delle_Finestre_km_177.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_20/Stage_20_KOM_Colle_delle_Finestre_km_177.csv\")"],"metadata":{"id":"Mr5cCnzAqhvC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_20_KOM_Sestrière_km_205.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_20/Stage_20_KOM_Sestrière_km_205.csv\")"],"metadata":{"id":"Dh6xYQrFq_VW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_20_Intermediate_Sprint_Rocca_Canavese_km_64.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_20/Stage_20_Intermediate_Sprint_Rocca_Canavese_km_64.csv\")"],"metadata":{"id":"rCJEhGQBq_Jz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_20_Intermediate_Sprint_Chiusa_di_San_Michele_km_137.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardinit/Data/Stage_20/Stage_20_Intermediate_Sprint_Chiusa_di_San_Michele_km_137.csv\")"],"metadata":{"id":"k9PCN8wuq-_H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_20_Maglia_Rosa.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_20/Stage_20_Maglia_Rosa.csv\")"],"metadata":{"id":"aDcvcDS2ryFe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_20_Maglia_Ciclamino.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_20/Stage_20_Maglia_Ciclamino.csv\")"],"metadata":{"id":"ETm_bWrwry_O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_20_Maglia_Azzurra.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_20/Stage_20_Maglia_Azzurra.csv\")"],"metadata":{"id":"rZXf5XeNrzgz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_19_Maglia_Rosa.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_20/Stage_19_Maglia_Rosa.csv\")"],"metadata":{"id":"lylkfuvFI4Pu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_19_Maglia_Ciclamino.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_20/Stage_19_Maglia_Ciclamino.csv\")"],"metadata":{"id":"qxl9jA-sI4Pw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_19_Maglia_Azzurra.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_20/Stage_19_Maglia_Azzurra.csv\")"],"metadata":{"id":"_LbK6RbbI4Pw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Stage 20:**"],"metadata":{"id":"9GgrunWCmRK7"}},{"cell_type":"code","source":["stages_info[10].to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_10/Stage_10_Info.csv\")"],"metadata":{"id":"Kvwc_n6BmRK7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stages_weather[10].to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_10/Stage_10_Weather.csv\")"],"metadata":{"id":"rKYECyH5mRK8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_10_Order_of_arrival.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_10/Stage_10_Order_of_arrival.csv\")"],"metadata":{"id":"tPM0Er4CmRK8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_10_Points_Stage_Standing.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_10/Stage_10_Points_Stage_Standing.csv\")"],"metadata":{"id":"Ha-2bfO6mRK8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_10_Maglia_Rosa.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_10/Stage_10_Maglia_Rosa.csv\")"],"metadata":{"id":"Mz1Qac-1mRK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_10_Maglia_Ciclamino.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_10/Stage_10_Maglia_Ciclamino.csv\")"],"metadata":{"id":"5eUooGHnmRK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_10_Maglia_Azzurra.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_10/Stage_10_Maglia_Azzurra.csv\")"],"metadata":{"id":"udK5oFCnmRK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_9_Maglia_Rosa.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_10/Stage_9_Maglia_Rosa.csv\")"],"metadata":{"id":"s75ajI1BmRK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_9_Maglia_Ciclamino.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_10/Stage_9_Maglia_Ciclamino.csv\")"],"metadata":{"id":"2AsfiCb4mRK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Stage_9_Maglia_Azzurra.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Stage_10/Stage_9_Maglia_Azzurra.csv\")"],"metadata":{"id":"816ygXeHmRK-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Gran Piemonte:**"],"metadata":{"id":"SEXDdqrwD6dj"}},{"cell_type":"code","source":["Gran_Piemonte_Info.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Gran_Piemonte/Gran_Piemonte_Info.csv\")"],"metadata":{"id":"RLk-x5JvEGy4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Gran_Piemonte_Weather.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Gran_Piemonte/Gran_Piemonte_Weather.csv\")"],"metadata":{"id":"x-fGPcPIEDvQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Gran_Piemonte_Order_of_arrival.to_csv(\"drive/MyDrive/DS Lab Project - Noè, Volpi Ghirardini/Data/Gran_Piemonte/Gran_Piemonte_Order_of_arrival.csv\")"],"metadata":{"id":"TSHWfR14EJE8"},"execution_count":null,"outputs":[]}]}